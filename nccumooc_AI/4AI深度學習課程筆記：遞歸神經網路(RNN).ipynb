{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 RNN(recurrent neural network)\n",
    "\n",
    "### **特點一：有記憶的神經網路。**\n",
    "  有別於以前的神經網路，不分順序相同筆資料輸入會得到一樣的值。\n",
    "  但RNN會記憶先前輸出結果，並回傳當成新的輸入。\n",
    "\n",
    "* 例子：對話機器人\n",
    "\n",
    "## 4.2 RNN的運用\n",
    "* 前次輸出與當次輸入各自權重，並加上偏值\n",
    "![RNN](4_1.jpg)\n",
    "\n",
    "* **限制：標準的RNN可能會遇到每次調整，造成難以訓練。因此現在操作上的RNN可能指的是以下兩種改良方式。**\n",
    "    - LSTM(Long Short Term Memory)\n",
    "    - GRU(Gated Recurrent Unit)\n",
    "    \n",
    "### **特點二：輸入值與輸出值可以為不同的類型的資料，如輸入圖片並輸出文字。**\n",
    "\n",
    "* 例子：\n",
    "    - 翻譯\n",
    "    - 生成影片描述\n",
    "    - 生成一段文字\n",
    "    - 完成一半的圖\n",
    "    - Andrej Karpathy(RNN有名推廣者)使用RNN模仿教科書與莎翁作品\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 RNN的應用：情意分析\n",
    "\n",
    "#### 情意分析：分析文本與評語，進行正負評的分類。\n",
    "    1. 問題：將一段文字透過函數學習，即可判斷內容為正負評。\n",
    "    2. 函數形式：文字段落-f()-正負評\n",
    "    3. 訓練資料：keras內有IMDB影評資料，訓練與測試資料各2.5萬筆。\n",
    "    4. 架構神經網路：\n",
    "        一萬個字=>X(embedding)=>RNN(150個RNN cell)=> D(1維數字)\n",
    "    5. 學習法：ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 做情意分析RNN神經網路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1)初始準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)讀入IMDB資料庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* num_words可以篩選文字出現的頻率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 9s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1)輸入資料\n",
    "這裡顯示的是文字編碼，在以下例子為1為出現頻率最高的字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1230,\n",
       " 3765,\n",
       " 566,\n",
       " 97,\n",
       " 189,\n",
       " 102,\n",
       " 86,\n",
       " 7,\n",
       " 32,\n",
       " 4,\n",
       " 973,\n",
       " 16,\n",
       " 55,\n",
       " 355,\n",
       " 18,\n",
       " 14,\n",
       " 20,\n",
       " 4,\n",
       " 64,\n",
       " 542,\n",
       " 173,\n",
       " 16,\n",
       " 4,\n",
       " 893,\n",
       " 2115,\n",
       " 5376,\n",
       " 250,\n",
       " 39,\n",
       " 8013,\n",
       " 4,\n",
       " 1362,\n",
       " 2,\n",
       " 14,\n",
       " 102,\n",
       " 47,\n",
       " 57,\n",
       " 599,\n",
       " 633,\n",
       " 6,\n",
       " 1317,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 189,\n",
       " 20,\n",
       " 57,\n",
       " 206,\n",
       " 57,\n",
       " 116,\n",
       " 5,\n",
       " 57,\n",
       " 836,\n",
       " 82,\n",
       " 6,\n",
       " 1317,\n",
       " 2,\n",
       " 3728,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 52,\n",
       " 284,\n",
       " 21,\n",
       " 29,\n",
       " 9,\n",
       " 38,\n",
       " 2245,\n",
       " 5,\n",
       " 1044,\n",
       " 11,\n",
       " 14,\n",
       " 15,\n",
       " 45,\n",
       " 619,\n",
       " 50,\n",
       " 71,\n",
       " 6,\n",
       " 171,\n",
       " 531,\n",
       " 15,\n",
       " 71,\n",
       " 424,\n",
       " 8,\n",
       " 30,\n",
       " 163,\n",
       " 6211,\n",
       " 4,\n",
       " 1629,\n",
       " 189,\n",
       " 212,\n",
       " 102,\n",
       " 5,\n",
       " 57,\n",
       " 31,\n",
       " 1498,\n",
       " 11,\n",
       " 4,\n",
       " 311,\n",
       " 13,\n",
       " 197,\n",
       " 15,\n",
       " 14,\n",
       " 20,\n",
       " 16,\n",
       " 1150,\n",
       " 1479,\n",
       " 5,\n",
       " 13,\n",
       " 161,\n",
       " 990,\n",
       " 692,\n",
       " 5,\n",
       " 1706,\n",
       " 12,\n",
       " 69,\n",
       " 77,\n",
       " 1194,\n",
       " 8,\n",
       " 3245,\n",
       " 2001,\n",
       " 553,\n",
       " 67,\n",
       " 14,\n",
       " 20,\n",
       " 48,\n",
       " 25,\n",
       " 423,\n",
       " 13,\n",
       " 131,\n",
       " 124,\n",
       " 51,\n",
       " 25,\n",
       " 122,\n",
       " 236,\n",
       " 1506,\n",
       " 198,\n",
       " 4,\n",
       " 64,\n",
       " 552,\n",
       " 7,\n",
       " 415,\n",
       " 37,\n",
       " 62,\n",
       " 169,\n",
       " 14,\n",
       " 20,\n",
       " 60,\n",
       " 2602,\n",
       " 629,\n",
       " 5,\n",
       " 615,\n",
       " 14,\n",
       " 9,\n",
       " 8,\n",
       " 25,\n",
       " 1230,\n",
       " 3765,\n",
       " 570,\n",
       " 231,\n",
       " 189,\n",
       " 102,\n",
       " 14,\n",
       " 20,\n",
       " 166,\n",
       " 2039,\n",
       " 168,\n",
       " 40,\n",
       " 2450,\n",
       " 5486,\n",
       " 3298]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 可以發現每筆影評長度並不一致，有待調整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218,189,141,550,147,43,123,562,233,130,"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(len(x_train[i]), end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) 輸出資料部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.3) 輸入前的資料處理\n",
    "* RNN可以接受不同長度的輸入，但仍要\n",
    "    - 文字長度要設立上限\n",
    "    - 把每段文字弄成一樣長，太短的補上0\n",
    "* keras會再將此輸入值轉成10000維向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3.1)建構神經網路\n",
    "\n",
    "    * embedding：將10000維向量壓到128維\n",
    "    * 用128個LSTM\n",
    "    * 最後output使用sigmoid送出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(10000,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3.2) 組裝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         1280000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 150)               167400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 1,447,551\n",
      "Trainable params: 1,447,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167400"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM 167400 3個gate*(128維+150個神經元參數+偏值)+...\n",
    "3*(128+150+1)*150 + (128+150+1)*150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4)訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angus\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 254s 10ms/step - loss: 0.4347 - accuracy: 0.7938\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 234s 9ms/step - loss: 0.2677 - accuracy: 0.8919\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 230s 9ms/step - loss: 0.1854 - accuracy: 0.9292\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 226s 9ms/step - loss: 0.1316 - accuracy: 0.9512\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 226s 9ms/step - loss: 0.0910 - accuracy: 0.9688\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 225s 9ms/step - loss: 0.0701 - accuracy: 0.9755\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 312s 12ms/step - loss: 0.0475 - accuracy: 0.9844\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 261s 10ms/step - loss: 0.0421 - accuracy: 0.9872\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 226s 9ms/step - loss: 0.0258 - accuracy: 0.9922\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 224s 9ms/step - loss: 0.0332 - accuracy: 0.9895\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 217s 9ms/step - loss: 0.0175 - accuracy: 0.9947\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 248s 10ms/step - loss: 0.0135 - accuracy: 0.9960\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 286s 11ms/step - loss: 0.0237 - accuracy: 0.9927\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 279s 11ms/step - loss: 0.0106 - accuracy: 0.9970\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 281s 11ms/step - loss: 0.0066 - accuracy: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1cc4862e9c8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "         batch_size=32,\n",
    "         epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5)檢視結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 57s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試資料的loss: 1.0617911480247975\n",
      "測試資料的正確率: 0.830079972743988\n"
     ]
    }
   ],
   "source": [
    "print(\"測試資料的loss:\", score[0])\n",
    "print(\"測試資料的正確率:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json= model.to_json()\n",
    "open('imdb_model_rnn.json', 'w').write(model_json)\n",
    "model.save_weights('imdb_rnn_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 另一種儲存神經網路的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('myrnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
